---
title: "1. dbtへの招待"
---

# 1. dbtへの招待

この章では、dbtが登場する前のデータパイプラインの課題と、dbtがどのようにそれらを解決するのかを理解しましょう。

## 1-1. データパイプラインの課題

あなたはデータアナリストとして、会社の売上データを分析する仕事を任されたとします。データは複数のシステムに散らばっていて、以下のような状況かもしれません：

```
📂 sql_queries/
├── daily_sales_v1.sql
├── daily_sales_v2.sql
├── daily_sales_final.sql
├── daily_sales_final_v2.sql
└── ...（以下数百ファイル）
```

「どのSQLが最新版？」「このSQLは何のために作ったんだっけ？」という状況に心当たりはありませんか？

:::message
これらの課題は、組織が大きくなるほど深刻になります。1人のアナリストなら頭で管理できていても、チームになると破綻します。
:::

## 1-2. dbtが解決する問題

dbtは、データパイプラインの課題を以下のように解決します：

| 課題 | 具体例 | dbtによる解決 |
|-----|--------|--------------|
| **SQLの乱立** | どのファイルが最新かわからない | Gitでバージョン管理 |
| **依存関係の不明確さ** | どのテーブルを先に作るべきか？ | `ref()`で自動解決 |
| **データ品質の欠如** | マイナスの売上に気づかない | テスト機能で自動検証 |
| **ドキュメント不足** | カラムの意味がわからない | 自動ドキュメント生成 |

### 解決のイメージ

```sql
-- Before: テーブル名を直接指定（依存関係が見えない）
SELECT * FROM customer_summary
JOIN order_aggregates

-- After: ref()で参照（dbtが依存関係を管理）
SELECT * FROM {{ ref('int_customer_summary') }}
JOIN {{ ref('int_order_aggregates') }}
```

## 1-3. ELTアプローチの理解

dbtを理解するには、ETLとELTの違いを理解する必要があります。

### 一言で言うと

- **ETL** = 「ロード**前**に変換」（事前変換）
- **ELT** = 「ロード**後**に変換」（後から変換）

### 従来のETL

```
[ソース] → [Extract] → [Transform] → [Load] → [DWH]
                         ↑
                    ETLツール
                  (Informatica等)
```

- データをウェアハウスにロードする前に変換
- 専用のETLツールが必要（高額、学習コストが高い）
- 複雑なGUIで設定

### モダンなELT（dbtが採用）

```
[ソース] → [Extract] → [Load] → [DWH] → [Transform]
                                    ↑
                                  dbt
                            (SQLで記述)
```

- まず生データをウェアハウスにロード
- ウェアハウス内でSQLを使って変換
- dbtは変換部分のみを担当

:::message alert
**なぜELTなのか？**

クラウドデータウェアハウス（BigQuery、Snowflake等）の登場により、ウェアハウス内での処理が高速・安価になりました。

例えばBigQueryなら：
1. Fivetran等で生データをロード
2. dbtでSQLを書いて変換
3. 変換結果をBIツールで可視化

この流れがすべてSQLだけで完結します。
:::

## 1-4. dbtを使うメリット

### SQLだけで完結

```sql
-- Pythonや他の言語を覚える必要がない
SELECT
    customer_id,
    SUM(amount) as total_amount
FROM {{ ref('stg_orders') }}
GROUP BY customer_id
```

データアナリストやデータサイエンティストは、新しい言語を覚えることなく、既存のSQLスキルを活かせます。

### ソフトウェアエンジニアリングのベストプラクティス

- **バージョン管理**: Gitでコードを管理
- **モジュール化**: 再利用可能なコンポーネント
- **テスト**: データ品質の自動チェック
- **CI/CD**: 継続的インテグレーション/デリバリー

### データパイプラインの民主化

これまでデータエンジニアだけが構築できたパイプラインを、アナリストも自分で構築・保守できるようになります。

**具体的な例**：
- 売上レポートの集計ロジックを変更したい → アナリストが自分でモデルを修正
- 新しいKPIを追加したい → SQLを書くだけで即座に追加
- データに不整合を見つけた → テストを追加して再発防止

## 1-5. 本書で学ぶこと

本書では、以下のステップでdbtを学びます：

1. **入門編**: dbtの概要と環境構築
2. **初級編**: 基本的なプロジェクト構築
3. **中級編**: 本格的な運用と高度な機能

それぞれの章で、実際に手を動かしながら学んでいきましょう。

## まとめ

- データパイプラインには「SQLの乱立」「依存関係」「データ品質」「ドキュメント」という課題がある
- dbtはこれらを「Git管理」「ref()」「テスト」「自動ドキュメント」で解決
- ETLは「事前変換」、ELTは「後から変換」
- SQLだけでデータパイプラインを構築できる

次の章では、dbtの概要をより詳しく見ていきます。
